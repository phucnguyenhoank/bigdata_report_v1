{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c70c606",
   "metadata": {},
   "source": [
    "# Xây dựng hệ thống gợi ý sản phẩm sử dụng tập dữ liệu Amazon Reviews' 23\n",
    "\n",
    "**Thành viên nhóm:**  \n",
    "Nguyễn Hoàng Phúc - 22110400  \n",
    "Phạm Trung Kỳ - 22110361  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b7296",
   "metadata": {},
   "source": [
    "## Mục lục\n",
    "- [1. Tóm tắt](#1-tóm-tắt)\n",
    "- [2. Giới thiệu](#2-giới-thiệu)\n",
    "- [3. Dữ liệu](#3-dữ-liệu)\n",
    "  - [3.1 Dữ liệu sử dụng trong dự án](#31-dữ-liệu-sử-dụng-trong-dự-án)\n",
    "  - [3.2 Dữ liệu cho mô hình SVD](#32-dữ-liệu-cho-mô-hình-svd)\n",
    "  - [3.3 Tiền xử lý dữ liệu](#33-tiền-xử-lý-dữ-liệu)\n",
    "- [4. Phương pháp](#4-phương-pháp)\n",
    "  - [4.1 Ý tưởng chung](#41-ý-tưởng-chung)\n",
    "  - [4.2 Matrix Factorization](#42-matrix-factorization)\n",
    "    - [4.2.1 SGD (Stochastic Gradient Descent)](#421-sgd-stochastic-gradient-descent)\n",
    "    - [4.2.2 ALS (Alternating Least Squares)](#422-als-alternating-least-squares)\n",
    "    - [4.2.3 SVD (Singular Value Decomposition)](#423-svd-singular-value-decomposition)\n",
    "  - [4.3 Locality Sensitive Hashing (LSH)](#43-locality-sensitive-hashing-lsh)\n",
    "  - [4.4 Neural Collaborative Filtering (NCF)](#44-neural-collaborative-filtering-ncf)\n",
    "- [5. Thực nghiệm, kết quả và thảo luận](#5-thực-nghiệm-kết-quả-và-thảo-luận)\n",
    "  - [5.1 Thiết lập thí nghiệm](#51-thiết-lập-thí-nghiệm)\n",
    "    - [A. Quy trình chung](#a-quy-trình-chung)\n",
    "    - [B. ALS (Alternating Least Squares)](#b-als-alternating-least-squares)\n",
    "    - [C. SGD (Stochastic Gradient Descent)](#c-sgd-stochastic-gradient-descent)\n",
    "    - [D. NCF (Neural Collaborative Filtering)](#d-ncf-neural-collaborative-filtering)\n",
    "    - [E. SVD (Singular Value Decomposition)](#e-svd-singular-value-decomposition)\n",
    "    - [F. LSH (Locality-Sensitive Hashing)](#f-lsh-locality-sensitive-hashing)\n",
    "  - [5.2 Kết quả](#52-kết-quả)\n",
    "- [6. Kết luận](#6-kết-luận)\n",
    "- [7. Phụ lục](#7-phụ-lục)\n",
    "  - [A. Chuẩn hóa dữ liệu theo item mean](#a-chuẩn-hóa-dữ-liệu-theo-item-mean)\n",
    "  - [B. Công thức cập nhật trong SGD](#b-công-thức-cập-nhật-trong-sgd)\n",
    "  - [C. Công thức cập nhật trong ALS (Alternating Least Squares)](#c-công-thức-cập-nhật-trong-als-alternating-least-squares)\n",
    "- [8. Đóng góp](#8-đóng-góp)\n",
    "- [9. Tham khao](#9-tham-khao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f19006",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Tóm tắt\n",
    "\n",
    "Hệ thống gợi ý sản phẩm (recommender systems) là thành phần then chốt cho các nền tảng thương mại điện tử, giúp cá nhân hóa trải nghiệm người dùng và tăng tỷ lệ chuyển đổi mua hàng. Dự án này xây dựng một hệ thống gợi ý sản phẩm sử dụng dữ liệu đánh giá từ **Amazon Reviews 2023**, tập con **Arts, Crafts & Sewing** (tổng ~1.7M đánh giá). Nhóm thử nghiệm các phương pháp cổ điển và hiện đại: **Matrix Factorization** (SVD, ALS tối ưu bằng alternating least squares), tối ưu trực tiếp bằng **SGD**, **Neural Collaborative Filtering (NCF)** để học mối quan hệ phi tuyến giữa user & item, và **LSH** để tăng tốc tìm kiếm sản phẩm tương tự. Dữ liệu được tiền xử lý (loại bỏ bản ghi thiếu, đánh chỉ số User/Item, chuẩn hóa rating, xử lý văn bản cho mô hình text-aware). Hiệu năng được đánh giá bằng MAE, RMSE cho dự đoán rating và P@K, NDCG@K cho xếp hạng gợi ý. Kết quả thực nghiệm cho thấy ALS cho MAE/RMSE tốt hơn SVD; mô hình NCF và ALS cho kết quả tốt tương tự nhau. Báo cáo mô tả chi tiết thiết kế thí nghiệm, siêu tham số, kết quả, phân tích quá khớp, các bước tối ưu và đề xuất cải tiến trong tương lai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3670bb4",
   "metadata": {},
   "source": [
    "## 2. Giới thiệu\n",
    "\n",
    "**Bài toán.** Với tập đánh giá $\\mathcal{D} = {(u, i, r_{ui})}$ (User ID, Item ID, Rating), mục tiêu là sẽ dự đoán rating cho các cặp $(u,i)$ chưa có và sinh ra danh sách top-K sản phẩm cho mỗi user sao cho phù hợp với sở thích.\n",
    "\n",
    "**Tại sao quan trọng.** Gợi ý cá nhân hóa giúp tăng trải nghiệm, tăng thời gian tương tác, và doanh thu. Bài toán thách thức do dữ liệu rất thưa (sparse), số lượng user/item lớn, và tính động của sở thích.\n",
    "\n",
    "**Input / Output.**\n",
    "\n",
    "* Input: ma trận đánh giá $R \\in \\mathbb{R}^{|U|\\times|I|}$ (sparse), metadata (title, main category, description,...), review text.\n",
    "* Output: (1) predicted rating $\\hat r_{ui}$ cho cặp chưa xuất hiện, (2) danh sách các item top-K gợi ý cho user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5bda0",
   "metadata": {},
   "source": [
    "## 3. Dữ liệu\n",
    "\n",
    "Trong dự án này, nhóm sử dụng **Amazon Reviews Dataset (2023)** được công bố bởi McAuley Lab (UCSD). Đây là một trong những tập dữ liệu gợi ý sản phẩm quy mô lớn nhất hiện nay, với hơn 571,54 triệu đánh giá được thu thập từ nhiều danh mục hàng hóa khác nhau. Mỗi bản ghi (record) bao gồm thông tin đa dạng như:\n",
    "\n",
    "* **User Reviews:** điểm đánh giá (rating), nội dung bình luận (review text), số lượt bình chọn “helpful”, v.v.\n",
    "* **Item Metadata:** thông tin mô tả, giá, hình ảnh sản phẩm, danh mục.\n",
    "* **Links:** dữ liệu quan hệ giữa sản phẩm và người dùng (ví dụ: “bought together”, “also viewed”).\n",
    "\n",
    "Tập dữ liệu đã được nhóm tác giả chia sẵn thành ba phần train, validation, và test dựa trên **Absolute-Timestamp Splitting**. Cụ thể, mỗi người dùng có một chuỗi tương tác theo thời gian, và các mốc thời gian $t_1$ và $t_2$ được định nghĩa như sau:\n",
    "\n",
    "* **Training part:** các tương tác có timestamp trong khoảng $(-\\infty, t_1)$\n",
    "* **Validation part:** các tương tác trong khoảng $[t_1, t_2)$\n",
    "* **Testing part:** các tương tác trong khoảng $[t_2, +\\infty)$\n",
    "\n",
    "Với tập dữ liệu năm 2023, các giá trị được cố định là $t_1 = 1628643414042$ và $t_2 = 1658002729837$.\n",
    "Cách chia này đảm bảo rằng dữ liệu mô phỏng thực tế, mô hình chỉ được huấn luyện trên dữ liệu quá khứ và đánh giá trên tương tác xảy ra sau đó, giúp kết quả phản ánh đúng tính chất dự đoán theo thời gian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd78cb6",
   "metadata": {},
   "source": [
    "### 3.1. Dữ liệu sử dụng trong dự án\n",
    "\n",
    "Nhóm chọn danh mục **“Arts, Crafts and Sewing”** làm tập chính để huấn luyện, với tổng cộng khoảng **1,8 triệu lượt đánh giá**, bao gồm:\n",
    "\n",
    "* **197.3K người dùng (users)**\n",
    "* **90.0K sản phẩm (items)**\n",
    "* **Tỷ lệ chia tập:** 1.4M (train) / 192.8K (validation) / 210.8K (test)\n",
    "\n",
    "Mỗi dòng dữ liệu bao gồm các trường chính sau:\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Trường</th>\n",
    "      <th>Mô tả</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td><code>user_id</code></td><td>Mã định danh người dùng</td></tr>\n",
    "    <tr><td><code>parent_asin</code></td><td>Mã sản phẩm</td></tr>\n",
    "    <tr><td><code>rating</code></td><td>Điểm đánh giá (1–5)</td></tr>\n",
    "    <tr><td><code>timestamp</code></td><td>Thời điểm đánh giá</td></tr>\n",
    "    <tr><td><code>history</code></td><td>Lịch sử các sản phẩm đã đánh giá trước đó</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "Ví dụ về một số dòng dữ liệu trong tập train:\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>user_id</th>\n",
    "      <th>parent_asin</th>\n",
    "      <th>rating</th>\n",
    "      <th>timestamp</th>\n",
    "      <th>history</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>AFKZENTNBQ7A7V7UX...</td>\n",
    "      <td>0913212148</td>\n",
    "      <td>5.0</td>\n",
    "      <td>1441260318000</td>\n",
    "      <td>NULL</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>AFKZENTNBQ7A7V7UX...</td>\n",
    "      <td>B0BGXTQLL1</td>\n",
    "      <td>5.0</td>\n",
    "      <td>1523092443644</td>\n",
    "      <td>0913212148</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>AFKZENTNBQ7A7V7UX...</td>\n",
    "      <td>B0BV5ZGRRM</td>\n",
    "      <td>5.0</td>\n",
    "      <td>1564347303691</td>\n",
    "      <td>0913212148 B0BGXT...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "Trong quá trình xử lý, nhóm chỉ sử dụng ba trường `user_idx`, `item_idx`, và `rating` cho các mô hình gợi ý chính (ALS, SGD, NCF, LSH). Riêng với **SVD**, do đặc thù thuật toán yêu cầu ma trận đánh giá đầy đủ, nhóm chuyển đổi dữ liệu sang dạng ma trận $R_{m \\times n}$ (người dùng × sản phẩm).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71e5e2",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2. Dữ liệu cho mô hình SVD\n",
    "\n",
    "Ma trận đầy đủ được tạo thành để sử dụng cho thuật toán SVD là khá lớn và vì hạn chế phần cứng, nhóm sử dụng danh mục nhỏ hơn là **“All_Beauty”**, có kích thước khiêm tốn hơn nhiều:\n",
    "\n",
    "* **253 người dùng**\n",
    "* **356 sản phẩm**\n",
    "* Dữ liệu được chia theo tỷ lệ 70% - 10% – 20% cho train – validation – test tương ứng.\n",
    "\n",
    "Danh mục này phù hợp để kiểm thử các thuật toán phân rã ma trận (Matrix Factorization) như **SVD** mà không gặp giới hạn về bộ nhớ hoặc thời gian huấn luyện.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792fe8a",
   "metadata": {},
   "source": [
    "### 3.3 Tiền xử lý dữ liệu\n",
    "\n",
    "Trong dữ liệu gốc, `user_id` và `parent_asin` là kiểu chuỗi không tiện cho việc đưa vào mô hình, `rating` cũng chưa được chuẩn hóa dẫn đến việc huấn luyện lâu hơn, giá trị rating từ 0 đến 5 tiềm ẩn bias, khó khăn trong việc xử lý vấn đề cold-start.  \n",
    "Mục tiêu là chuẩn hóa rating và tạo chỉ số user/item nhất quán giữa các split để phục vụ việc huấn luyện mô hình, xử lý vấn đề cold-start khi user/item mới xuất hiện từ tập valid hoặc test không có trong tập train.\n",
    "\n",
    "  **Đọc dữ liệu**\n",
    "\n",
    "   * Dữ liệu gồm ba split `train/valid/test` (giữ nguyên như mục 3.1).\n",
    "   * Dữ liệu được đọc bằng PySpark để xử lý hiệu quả các tập dữ liệu lớn.\n",
    "   * Ta xử lý riêng biệt user và item, nhưng chung quy trình.\n",
    "\n",
    "  **Tạo mapping user/item**\n",
    "\n",
    "   * Lấy tập hợp tất cả user/item xuất hiện trong các split, loại bỏ lặp lại, ta được tập chứa các user/item id.\n",
    "   * Gán `userIndex` và `itemIndex` (unique integer) cho mỗi user/item, nhằm đảm bảo mapping nhất quán giữa các split và các lần chạy.\n",
    "   * Lưu mapping ra file để tái sử dụng cho mô hình.\n",
    "\n",
    "   **Chuẩn hóa rating theo item (item-mean normalization)**\n",
    "\n",
    "   * Tính `item_mean = avg(rating)` trên train; tính `global_mean` trên train để dùng khi item mới xuất hiện trong valid/test.\n",
    "   * Với mỗi split:\n",
    "\n",
    "     * Gán index user/item theo mapping.\n",
    "     * Gán `item_mean` cho mỗi record; nếu item chưa xuất hiện trong train → dùng `global_mean`.\n",
    "     * Sinh cột chuẩn hóa: `rating_norm = rating - item_mean`.\n",
    "\n",
    "   **Lưu dữ liệu tiền xử lý**\n",
    "\n",
    "   * Lưu `item_means` và DataFrame đã chuẩn hóa (train/valid/test) để dùng trực tiếp cho mô hình.\n",
    "\n",
    "   **Một số kết quả của quá trình xử lý dữ liệu**\n",
    "   * User mapping\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align:left;\">user_id</th>\n",
    "      <th style=\"text-align:right;\">userIndex</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td>AE22236AFRRSMQIKG...</td><td>0</td></tr>\n",
    "    <tr><td>AE222H3FGXWLHRFUM...</td><td>1</td></tr>\n",
    "    <tr><td>AE224QIIILW6WVFAE...</td><td>2</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "  * Rating norm\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>itemIndex</th>\n",
    "    <th>parent_asin</th>\n",
    "    <th>userIndex</th>\n",
    "    <th>user_id</th>\n",
    "    <th>rating</th>\n",
    "    <th>rating_norm</th>\n",
    "    <th>item_mean</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>89574</td><td>B0C7CXW1JB</td><td>193523</td><td>AHXOCRWNKC552ESFF...</td><td>4.0</td><td>-0.7849872773536894</td><td>4.7849872773536894</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>21220</td><td>B00N9RIBIO</td><td>41477</td><td>AEV2AM5IEUVKSKLEJ...</td><td>5.0</td><td>0.5571428571428569</td><td>4.442857142857143</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>89056</td><td>B0C4KB3GMD</td><td>193989</td><td>AHXY3L4R6MASA7JH4...</td><td>1.0</td><td>-3.0491803278688527</td><td>4.049180327868853</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>75509</td><td>B09HBS73N9</td><td>183561</td><td>AHR7OPTZYKDBAAJQW...</td><td>5.0</td><td>0.4991011434207744</td><td>4.500898856579226</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>77422</td><td>B09PFQ3NJW</td><td>970</td><td>AE2OBGULEEQ6SQPV6...</td><td>5.0</td><td>0.4991011434207744</td><td>4.500898856579226</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49883795",
   "metadata": {},
   "source": [
    "## 4. Phương pháp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd5f49",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Ý tưởng chung\n",
    "\n",
    "Mỗi user $u$ và item $i$ được mô tả bằng vector đặc trưng $p_u, q_i \\in \\mathbb{R}^k$. Giá trị phù hợp (compatibility) được tính bằng dot product: $\\hat r_{ui} = p_u^\\top q_i$. Với NCF dùng mạng phi tuyến $f(p_u, q_i)$.  \n",
    "Các phương pháp được sử dụng ở đây sẽ học các vector đặc trưng từ dữ liệu đánh giá của những người dùng với những item một cách tự động.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990e36e",
   "metadata": {},
   "source": [
    "### 4.2 Matrix Factorization\n",
    "\n",
    "Matrix Factorization là cách biểu diễn ma trận user-item **dưới dạng tích của hai ma trận nhỏ hơn**:\n",
    "\n",
    "$$\n",
    "R \\approx P Q^\\top\n",
    "$$\n",
    "\n",
    "* $R$ là ma trận rating gốc (user × item).\n",
    "* $P$ là ma trận **user latent factors** (mỗi user thành một vector đặc trưng).\n",
    "* $Q$ là ma trận **item latent factors** (mỗi item thành một vector đặc trưng).\n",
    "\n",
    "Các thuật toán MF sẽ cố gắng tìm $P$ và $Q$ sao cho **tích $P Q^\\top$ dự đoán rating gần đúng với rating thật**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6e3d0",
   "metadata": {},
   "source": [
    "#### 4.2.1. SGD (Stochastic Gradient Descent)\n",
    "\n",
    "* Ý tưởng: **cập nhật từng user và item từng bước** dựa trên sai số dự đoán.\n",
    "* Sai số dự đoán cho user $u$ với item $i$:\n",
    "\n",
    "$$\n",
    "e_{ui} = r_{ui} - p_u^\\top q_i\n",
    "$$\n",
    "\n",
    "* Cập nhật vector latent với learning rate $\\eta$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p_u &\\leftarrow p_u + \\eta (e_{ui} q_i - \\lambda p_u)\\newline\n",
    "q_i &\\leftarrow q_i + \\eta (e_{ui} p_u - \\lambda q_i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* Giải thích:\n",
    "\n",
    "  * $e_{ui} q_i$ và $e_{ui} p_u$ giúp giảm sai số dự đoán.\n",
    "  * $\\lambda p_u$ và $\\lambda q_i$ là regularization để tránh overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937d8e0",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.2.2. ALS (Alternating Least Squares)\n",
    "\n",
    "* Ý tưởng là thay phiên nhau tối ưu $P$ rồi $Q$**.\n",
    "* Khi $Q$ cố định, mỗi vector $p_u$ được tính bằng công thức **least squares**:\n",
    "\n",
    "$$\n",
    "p_u = (Q_{u}^\\top Q_{u} + \\lambda I)^{-1} Q_{u}^\\top r_u\n",
    "$$\n",
    "\n",
    "* Trong đó:\n",
    "\n",
    "  * $Q_u$ là ma trận chứa các $q_i$ mà user $u$ đã đánh giá.\n",
    "  * $r_u$ là vector rating quan sát của user $u$.\n",
    "* Tương tự, khi $P$ cố định, cập nhật $Q$.\n",
    "* Ưu điểm là dễ song song hóa, xử lý ma trận thưa tốt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae83ae5",
   "metadata": {},
   "source": [
    "#### 4.2.3. SVD (Singular Value Decomposition)\n",
    "\n",
    "* Ý tưởng là tách ma trận rating $R \\in \\mathbb{R}^{m \\times n}$ thành ba ma trận:\n",
    "  $$\n",
    "  R \\approx U \\Sigma V^\\top\n",
    "  $$\n",
    "\n",
    "  * $U \\in \\mathbb{R}^{m \\times k}$: đặc trưng người dùng\n",
    "  * $\\Sigma \\in \\mathbb{R}^{k \\times k}$: giá trị kỳ dị\n",
    "  * $V \\in \\mathbb{R}^{n \\times k}$: đặc trưng sản phẩm\n",
    "\n",
    "* **Truncated SVD:** chỉ giữ $k \\ll \\min(m, n)$ thành phần chính → giảm nhiễu, giảm chiều, tăng tốc.\n",
    "\n",
    "* Kết quả ta được:\n",
    "  $$\n",
    "  \\hat{R} = U \\Sigma V^\\top\n",
    "  $$\n",
    "  với $\\hat{r}_{ui}$ là rating dự đoán; các hàng của $U, V$ là embedding của user và item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2294cde",
   "metadata": {},
   "source": [
    "### 4.3 Locality Sensitive Hashing (LSH)\n",
    "\n",
    "Ý tưởng:\n",
    "\n",
    "* LSH là kỹ thuật để tìm các vector gần nhau trong không gian lớn nhanh hơn so với tính toán tất cả cặp.\n",
    "* Cách làm: ánh xạ mỗi vector vào một \"bucket\" sao cho các vector gần nhau thường rơi vào cùng bucket.\n",
    "* Ứng dụng:\n",
    "\n",
    "  * Tìm **nearest neighbors xấp xỉ** (approximate nearest neighbors).\n",
    "  * Dùng cho item-based KNN hoặc tạo candidates trước khi xếp hạng bằng model chính.\n",
    "  * Gợi ý top sản phẩm liên quan.\n",
    "\n",
    "Cách hoạt động:\n",
    "\n",
    "1. Chia không gian embedding bằng cách sinh ra một hoặc nhiều tập các mặt phẳng ngẫu nhiên (hyperplane).\n",
    "2. Với mỗi vector:\n",
    "   * Kiểm tra nó nằm phía nào của mỗi mặt phẳng (ví dụ: >0 hay <0).\n",
    "   * Chuyển mỗi vector thành chuỗi nhị phân (0/1) → **hash code**.\n",
    "3. Các vector có hash code giống nhau sẽ vào cùng bucket.\n",
    "4. Khi vector mới vào sẽ được hash thành hashcode và thực hiện KNN với các vector trong bucket tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f72a4a",
   "metadata": {},
   "source": [
    "### 4.4 Neural Collaborative Filtering (NCF)\n",
    "\n",
    "Ý tưởng của việc sử dụng mạng neural network là để học mối quan hệ phi tuyến giữa các cặp vector embedding user $u$ và item $i$ trong việc dự đoán rating $\\hat r_{ui}$.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "* Mỗi user $u$ được ánh xạ thành vector embedding $p_u$\n",
    "* Mỗi item $i$ được ánh xạ thành vector embedding $p_i$\n",
    "* Các vector embedding này được khởi tạo ngẫu nhiên và sẽ được cải thiện dần khi mô hình học.\n",
    "\n",
    "**Kết hợp embedding:**\n",
    "\n",
    "* Ghép vector user và item thành một vector chung:\n",
    "  $$\n",
    "  x = [p_u, p_i]\n",
    "  $$\n",
    "* Vector này đại diện cho tương tác giữa user và item.\n",
    "\n",
    "**MLP (Multi-Layer Perceptron):**\n",
    "\n",
    "* Dữ liệu đi qua các lớp phi tuyến liên tiếp (Linear + Activation + Dropout/BatchNorm)\n",
    "* MLP học cách ánh xạ từ vector embedding sang rating dự đoán, khám phá các tương tác phi tuyến phức tạp hơn giữa user và item.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "* Lớp cuối cùng trả về **rating dự đoán** $\\hat r_{ui}$\n",
    "* Sử dụng **MSE loss** khi training để mạng học dự đoán rating thật với AdamW optimizer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41724b6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5. Thực nghiệm, kết quả và thảo luận"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d39323",
   "metadata": {},
   "source": [
    "### 5.1 Thiết lập thí nghiệm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02cfb61-4cf3-4b78-9b57-766e6debbbfb",
   "metadata": {},
   "source": [
    "\n",
    "#### A. Quy trình chung\n",
    "\n",
    "* **Split**: train/valid/test giữ nguyên theo mục 3.1.\n",
    "* **Metrics chính**:\n",
    "  * Regression: **MAE**, **RMSE**:  \n",
    "    $\\mathrm{MAE} = \\frac{1}{N}\\sum |r_{ui}-\\hat r_{ui}|$,  \n",
    "    $\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum (r_{ui}-\\hat r_{ui})^2}$.  \n",
    "  * Ranking: **Precision@K**, **NDCG@K**:  \n",
    "    $\\mathrm{DCG}_p = \\sum_{i=1}^p \\frac{rel_i}{\\log_2(i+1)}$,  \n",
    "    $\\mathrm{NDCG}_p = \\frac{\\mathrm{DCG}_p}{\\mathrm{IDCG}_p}$.  \n",
    "    \n",
    "* **Pipeline experiment**:\n",
    "\n",
    "  1. Load dữ liệu đã tiền xử lý ở mục 3.3.\n",
    "  2. Huấn luyện mô hình trên train, validation để chọn hyperparameter/early stopping, và cuối cùng đánh giá trên tập test.\n",
    "  3. Lưu checkpoint, lịch sử training, kết quả experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e52e8",
   "metadata": {},
   "source": [
    "#### B. ALS (Alternating Least Squares)\n",
    "\n",
    "Nhóm sử dụng **ALS** trong Spark để huấn luyện mô hình phân rã ma trận, với mục tiêu tối ưu các siêu tham số `rank`, `regParam`, và `maxIter`. Quá trình tìm kiếm được thực hiện bằng **grid search** trên các giá trị: `rank = 10`, `regParam ∈ {0.01, 0.1, 1.0}`, và `maxIter ∈ {5, 10, 15}`. Mỗi tổ hợp được huấn luyện trên tập train và đánh giá trên tập validation bằng các độ đo RMSE và MAE.\n",
    "\n",
    "Kết quả cho thấy cấu hình **rank = 10, regParam = 1.0, maxIter = 10–15** đạt hiệu năng tốt nhất, với **RMSE=1.1078** và **MAE=0.7635** cân bằng giữa train và validation, cho thấy việc tăng giá trị regularization giúp giảm hiện tượng overfitting rõ rệt so với các giá trị nhỏ hơn. Mô hình cũng đạt **0.9821 NDCG@10** và **0.7952 Precision@10** trên tập test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c3554",
   "metadata": {},
   "source": [
    "<img src=\"images/als_train_rmse_heatmap.png\" alt=\"ALS Train RMSE Heatmap\" width=\"650\">  \n",
    "\n",
    "**Hình 1.** Phân bố **RMSE trên tập huấn luyện** của mô hình ALS theo các giá trị siêu tham số.  \n",
    "_Biểu đồ heatmap thể hiện sai số RMSE tương ứng với từng cặp (maxIter, hệ số regularization λ), cho thấy mức độ hội tụ và khả năng khớp dữ liệu huấn luyện của mô hình._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eecab",
   "metadata": {},
   "source": [
    "<img src=\"images/als_valid_rmse_heatmap.png\" alt=\"ALS Validation RMSE Heatmap\" width=\"650\">  \n",
    "\n",
    "**Hình 2.** Phân bố **RMSE trên tập kiểm định** của mô hình ALS theo các giá trị siêu tham số.  \n",
    "_Biểu đồ cho thấy ảnh hưởng của regularization và số vòng lặp đến khả năng tổng quát hóa của mô hình; λ lớn giúp giảm sai số kiểm định và hạn chế overfitting._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5f1d1",
   "metadata": {},
   "source": [
    "<img src=\"images/als_train_valid_rmse_vs_iter.png\" alt=\"ALS Train vs Validation RMSE\" width=\"650\">  \n",
    "\n",
    "**Hình 3.** So sánh **RMSE giữa tập huấn luyện và tập kiểm định** theo số vòng lặp `maxIter` và các giá trị regularization λ.  \n",
    "_Biểu đồ lineplot cho thấy xu hướng hội tụ: RMSE tập huấn luyện giảm rất nhẹ khi tăng số vòng lặp, trong khi RMSE tập kiểm định ổn định hơn với regularization cao giảm mạnh overfitting, thể hiện khả năng tổng quát hóa của mô hình._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e0755d",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/als_train_valid_test_metrics.png\" alt=\"ALS Train, Validation, Test Metrics\" width=\"650\">  \n",
    "\n",
    "**Hình 4.** So sánh **RMSE và MAE trên các tập Train, Validation và Test**.  \n",
    "_Biểu đồ barplot tổng hợp giúp đánh giá hiệu năng chung của mô hình trên tất cả các tập dữ liệu, đồng thời quan sát sự cân bằng giữa huấn luyện và kiểm định, cũng như khả năng dự đoán trên tập Test._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d623fe",
   "metadata": {},
   "source": [
    "Khi regParam nhỏ (0.01–0.1), mô hình đạt sai số huấn luyện rất thấp nhưng sai số kiểm định cao, cho thấy hiện tượng overfitting rõ rệt. Khi tăng regParam lên 1.0, sai số huấn luyện tăng nhẹ trong khi sai số kiểm định giảm và ổn định hơn, chứng tỏ mô hình tổng quát hóa tốt hơn. Ngoài ra, việc tăng maxIter giúp mô hình hội tụ tốt hơn ở các giá trị nhỏ, nhưng ảnh hưởng không đáng kể khi regParam cao. Nhìn chung, cấu hình rank = 10, regParam = 1.0, maxIter = 10–15 cho kết quả cân bằng và đáng tin cậy nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a8ebe",
   "metadata": {},
   "source": [
    "<img src=\"images/rating_distribution.png\" alt=\"Rating Distribution\" width=\"650\">  \n",
    "\n",
    "\n",
    "**Hình 5.** Phân phối điểm đánh giá (rating distribution) trong tập dữ liệu.  \n",
    "_Biểu đồ histogram thể hiện tần suất xuất hiện của từng mức rating từ 1 đến 5._\n",
    "\n",
    "\n",
    "Phân phối điểm đánh giá bị lệch phải, trong đó rating 4 và 5 chiếm tỷ lệ lớn nhất, tiếp đến là rating 1, 3 và 2 thấp hơn nhiều. Mô hình dự đoán tập trung chủ yếu trong khoảng 4.5–5, đạt đỉnh ở 4.5, cho thấy mô hình có xu hướng định giá các sản phẩm ở mức cao, phản ánh dữ liệu huấn luyện bị thiên lệch về các đánh giá tích cực. Điều này nhấn mạnh tầm quan trọng của việc sử dụng regularization hoặc normalization để giảm sai lệch trong dự đoán và cải thiện khả năng tổng quát hóa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c57572",
   "metadata": {},
   "source": [
    "#### C. SGD (Stochastic Gradient Descent)\n",
    "\n",
    "\n",
    "Trong quá trình huấn luyện mô hình phân rã ma trận bằng thuật toán SGD, nhóm thử nghiệm hai bộ siêu tham số để tìm cấu hình tối ưu. Ở bộ đầu tiên $K = 30, lr = 0.007, λ = 0.02$, validation RMSE gần như không đổi, cho thấy hiện tượng underfitting do số chiều ẩn và tốc độ học còn thấp. Khi tăng lên $K = 50, lr = 0.01, λ = 0.05$, mô hình cải thiện rõ rệt, đạt MAE = 0.704, RMSE = 1.0948, Precision@K = 0.8878 và NDCG@K = 0.9819. Do validation loss đã bão hòa, nhóm dừng việc tinh chỉnh thêm vì mô hình đã đạt mức tổng quát hóa tốt, tránh overfitting và tốn chi phí huấn luyện không cần thiết.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b908a",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/sgd_rmse_mae_train_valid_loss.png\" alt=\"Training and Validation Loss of SGD\" width=\"650\">  \n",
    "\n",
    "\n",
    "**Hình 6.** Biểu đồ huấn luyện mô hình SGD – train loss và validation loss theo số epoch.\n",
    "\n",
    "\n",
    "Về RMSE thì biểu đồ cho thấy train loss giảm nhanh, trong khi validation loss hầu như không giảm đáng kể. Điều này cho thấy dữ liệu tương đối đơn giản, khiến mô hình hội tụ sớm và có overfitting rõ rệt. Tuy nhiên, khoảng cách nhỏ giữa RMSE train và validation loss cũng gợi ý rằng mô hình đã gần đạt giới hạn hiệu năng với cấu hình siêu tham số hiện tại. Với MAE loss thì ngoài việc có giá trị thấp hơn RMSE thì cũng cho một hình dáng đồng nhất.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16be70",
   "metadata": {},
   "source": [
    "#### D. NCF (Neural Collaborative Filtering)\n",
    "\n",
    "Với learning rate = 0.0001, mô hình cho thấy RMSE trên tập huấn luyện giảm mạnh và nhanh chóng đạt mức rất thấp, trong khi RMSE trên tập validation lại tăng dần theo epoch. Hiện tượng này thể hiện rõ ràng tình trạng overfitting: mô hình học thuộc dữ liệu huấn luyện nhưng không khái quát được cho dữ liệu mới.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c3cbc",
   "metadata": {},
   "source": [
    "<img src=\"images/ncf_rmse_train_valid_loss_1.png\" alt=\"Training and Validation Loss of NCF\" width=\"650\">\n",
    "\n",
    "**Hình 7.** Biểu đồ RMSE trên tập huấn luyện và kiểm định của mô hình NCF $lr = 0.0001$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b3423",
   "metadata": {},
   "source": [
    "Ngược lại, khi learning rate = 0.001, cả train RMSE và validation RMSE đều ổn định hơn. Mô hình hội tụ nhanh ở giai đoạn đầu, RMSE trên tập huấn luyện giảm đều đến mức hợp lý, còn RMSE trên tập validation giữ ổn định quanh mức thấp (~1.21), chứng tỏ khả năng tổng quát tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f05ab3",
   "metadata": {},
   "source": [
    "<img src=\"images/ncf_rmse_mae_train_valid_loss.png\" alt=\"Training and Validation Loss of NCF\" width=\"650\">\n",
    "\n",
    "**Hình 8.** Biểu đồ RMSE và MAE trên tập huấn luyện và kiểm định của mô hình NCF $lr = 0.001$.\n",
    "\n",
    "Do mạng NCF đã được thiết kế khá sâu và phức tạp (3 tầng ẩn [128, 64, 32] kèm BatchNorm và Dropout), năng lực biểu diễn của mô hình đã rất mạnh. Việc thử thêm các hyperparameter khác (như tăng số tầng, thay đổi dropout hay LR khác) nhiều khả năng chỉ làm mất ổn định huấn luyện hoặc tăng overfitting, mà không cải thiện đáng kể hiệu suất.\n",
    "Vì vậyLR = 0.001 giúp mô hình cân bằng giữa tốc độ học và khả năng khái quát, trong khi LR = 0.0001 khiến mô hình học quá kỹ dữ liệu train và mất tính tổng quát, kết quả cuối cùng trên tập test đạt MAE = 0.7382, RMSE = 1.0878, Precision@K = 0.7952, và NDCG@K = 0.982\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3aaada",
   "metadata": {},
   "source": [
    "#### D. SVD (Singular Value Decomposition)\n",
    "\n",
    "Trong thí nghiệm này, nhóm áp dụng phương pháp phân rã ma trận SVD thuần túy, không điều chỉnh các siêu tham số như số chiều tiềm ẩn hay hệ số regularization. Mục tiêu nhằm đánh giá khả năng nén thông tin và tái tạo ma trận đánh giá dựa trên các thành phần đặc trưng chính (singular values).\n",
    "Trên tập dữ liệu có quy mô nhỏ hơn đáng kể so với bộ sử dụng cho NCF và SGD, SVD đạt **MAE = 0.7694**, **RMSE = 1.0634**, **Precision@10 = 0.2064** và **NDCG@K = 0.9651**. Kết quả này cho thấy dù chỉ áp dụng phân rã cơ bản, mô hình vẫn duy trì độ chính xác dự đoán tương đối ổn định. RMSE và MAE ở mức thấp phản ánh khả năng tái tạo tốt, trong khi NDCG@K cao chứng tỏ SVD vẫn sắp xếp sản phẩm phù hợp với sở thích người dùng. Dù Precision@K còn hạn chế và dữ liệu nhỏ làm giảm tính tổng quát, kết quả này vẫn minh chứng cho vai trò nền tảng của SVD trong các hệ thống gợi ý. Việc không tinh chỉnh thêm siêu tham số là hợp lý vì mục tiêu chính là kiểm chứng khả năng biểu diễn tiềm ẩn của mô hình, không phải tối ưu hóa hiệu suất tuyệt đối.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d70474",
   "metadata": {},
   "source": [
    "#### F. LSH (Locality-Sensitive Hashing)\n",
    "\n",
    "Để tăng tốc việc tìm kiếm các item tương tự dựa trên vector embedding (user hoặc item), nhóm áp dụng **BucketedRandomProjectionLSH** với `bucketLength = 2.0` và `numHashTables = 3`. Tập dữ liệu gồm ~79k item vector 10 chiều, kết hợp metadata như `title`, `main_category` và `store`.\n",
    "\n",
    "Mô hình được huấn luyện trên toàn bộ tập vector, sau đó thực hiện truy vấn top-5 items gần nhất cho các vector user và item. Kết quả cho thấy LSH trả về các vector rất gần với truy vấn (Euclidean distance gần 0) trong thời gian trung bình ~0.91–1.08 giây, phù hợp với các ứng dụng gợi ý trực tuyến.\n",
    "\n",
    "Cấu hình hiện tại cân bằng tốt giữa độ chính xác và tốc độ truy vấn, đồng thời giúp tránh tính toán brute-force trên toàn bộ tập dữ liệu lớn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254a701",
   "metadata": {},
   "source": [
    "### 5.2 Kết quả\n",
    "\n",
    "Bảng 5.2 tổng hợp hiệu năng của các mô hình gợi ý sản phẩm trên tập dữ liệu *Arts_Crafts_and_Sewing*, bao gồm MAE, RMSE, Precision@10, NDCG@10 và **Overall Score** — chỉ số tổng hợp đánh giá toàn diện khả năng dự đoán và xếp hạng của mô hình.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Mô hình</th>\n",
    "      <th>MAE</th>\n",
    "      <th>RMSE</th>\n",
    "      <th>Precision@10</th>\n",
    "      <th>NDCG@10</th>\n",
    "      <th>Overall Score</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td>SVD</td><td>0.7694</td><td>1.0634</td><td>0.2064</td><td>0.9651</td><td>0.664</td></tr>\n",
    "    <tr><td>SGD</td><td>0.7040</td><td>1.0948</td><td>0.8878</td><td>0.9819</td><td>0.882</td></tr>\n",
    "    <tr><td>ALS</td><td>0.7635</td><td>1.1078</td><td>0.7952</td><td>0.9821</td><td>0.855</td></tr>\n",
    "    <tr><td>NCF</td><td>0.7382</td><td>1.0878</td><td>0.7952</td><td>0.9820</td><td>0.861</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "Công thức tính Overall Score:\n",
    "\n",
    "$$\n",
    "  \\text{Overall Score} = 0.4 \\times \\text{RMSE norm} + 0.4 \\times \\text{Precision@10} + 0.2 \\times \\text{NDCG@10}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  \\text{RMSE norm} = 1 - \\frac{\\text{RMSE} - \\min(\\text{RMSE})}{\\max(\\text{RMSE}) - \\min(\\text{RMSE})}\n",
    "$$\n",
    "\n",
    "Trong đó, RMSEnorm được đảo lại để giá trị RMSE thấp tương ứng với score cao hơn. Overall Score kết hợp cả khả năng dự đoán chính xác rating và khả năng xếp hạng top-K items, cho phép so sánh tổng thể giữa các mô hình.\n",
    "\n",
    "Từ bảng trên, có thể thấy **SGD đạt Overall Score cao nhất (0.882)**, nhờ kết hợp tốt giữa độ chính xác rating (MAE thấp) và khả năng xếp hạng top-K (Precision@10 cao), trong khi **SVD** có Overall Score thấp nhất (0.664) do Precision@10 kém. **ALS** và **NCF** thể hiện hiệu năng ổn định, với Overall Score lần lượt là 0.855 và 0.861."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cf7c4",
   "metadata": {},
   "source": [
    "<img src=\"images/model_comparison.png\" alt=\"Model Comparison\" width=\"650\">\n",
    "\n",
    "**Hình 9.** So sánh hiệu năng giữa các mô hình gợi ý sản phẩm.  \n",
    "_Biểu đồ thể hiện giá trị NDCG@10 và Precision@10 của các mô hình SVD, SGD, ALS, và NCF trên tập dữ liệu Arts_Crafts_and_Sewing._\n",
    " \n",
    "Mô hình SGD đạt Precision@10 cao nhất và NDCG@10 gần cao nhất, cho thấy khả năng xếp hạng top-K items chính xác hơn so với các mô hình khác. ALS và NCF có hiệu năng ổn định ở cả hai thước đo, với Precision@10 và NDCG@10 gần như bằng nhau, cho thấy cả hai mô hình đều mạnh trong việc duy trì ranking tổng thể. Trong khi đó, SVD có Precision@10 thấp nhất mặc dù NDCG@10 vẫn tương đối cao, chỉ ra rằng mô hình này bị ảnh hưởng rất nhiều bởi nhiễu do ma trận thưa, khó phân biệt các item hàng đầu nhưng vẫn giữ được ranking chung tương đối.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42f90e",
   "metadata": {},
   "source": [
    "## 6. Kết luận\n",
    "\n",
    "Nhóm đã triển khai và so sánh bốn mô hình gợi ý sản phẩm trên tập dữ liệu *Amazon Arts_Crafts_and_Sewing*, bao gồm SVD, SGD, ALS và NCF. Dựa trên chỉ số tổng hợp **Overall Score**, mô hình **SGD** đạt kết quả cao nhất (**0.882**), thể hiện khả năng cân bằng tốt giữa độ chính xác dự đoán (MAE thấp nhất) và khả năng xếp hạng top-K (Precision@10 cao). **ALS** và **NCF** đạt hiệu năng tương đối ổn định với Overall Score lần lượt là **0.855** và **0.861**, cho thấy hai mô hình này vẫn duy trì khả năng xếp hạng tốt dù độ sai số dự đoán cao hơn. Trong khi đó, **SVD** cho thấy hạn chế với Overall Score chỉ **0.664**, chủ yếu do Precision@10 thấp, phản ánh nhược điểm của phương pháp tuyến tính trong việc học mối quan hệ phức tạp giữa người dùng và sản phẩm.\n",
    "\n",
    "Hướng phát triển tiếp theo của đề tài tập trung vào việc nâng cao chất lượng gợi ý và khả năng ứng dụng trong thực tế. Trước hết, nhóm dự kiến tối ưu hóa các vector embedding của người dùng và sản phẩm, đồng thời tích hợp thêm các đặc trưng nội dung hoặc thông tin meta-data để cải thiện khả năng biểu diễn của mô hình. Bên cạnh đó, hệ thống có thể được mở rộng thành một pipeline hai giai đoạn, trong đó bước đầu sử dụng các phương pháp như LSH hoặc KNN để tạo tập ứng viên (candidate generation), sau đó áp dụng NCF hoặc các mô hình học sâu khác cho bước xếp hạng (ranking), nhằm tăng hiệu quả gợi ý top-K. Cuối cùng, nếu có dữ liệu người dùng thực tế, nhóm sẽ triển khai A/B testing để đánh giá khách quan hiệu quả của mô hình trong môi trường ứng dụng thật.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e31c4d",
   "metadata": {},
   "source": [
    "## 7. Phụ lục"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6919a3",
   "metadata": {},
   "source": [
    "### A. Chuẩn hóa dữ liệu theo item mean\n",
    "\n",
    "Gọi:\n",
    "\n",
    "* $r_{ui}$ là rating gốc của user $u$ cho item $i$,\n",
    "* $I_u, U_i$ là tập các user và item tương ứng,\n",
    "* $ \\mu_i $ là rating trung bình của item $i$ trên tập train:\n",
    "  $$\n",
    "  \\mu_i = \\frac{1}{|U_i|} \\sum_{u \\in U_i} r_{ui}.\n",
    "  $$\n",
    "\n",
    "Sau đó, rating được chuẩn hóa thành:\n",
    "$$\n",
    "r^{\\text{norm}}*{ui} = r*{ui} - \\mu_i.\n",
    "$$\n",
    "\n",
    "* Nếu item mới xuất hiện trong tập validation hoặc test mà không có giá trị trung bình từ train, nhóm sử dụng **global mean** $\\mu_{\\text{global}}$:\n",
    "  $$\n",
    "  r^{\\text{norm}}*{ui} =\n",
    "  \\begin{cases}\n",
    "  r*{ui} - \\mu_i, & \\text{nếu } i \\in \\text{train items},\\newline\n",
    "  r_{ui} - \\mu_{\\text{global}}, & \\text{nếu } i \\notin \\text{train items}.\n",
    "  \\end{cases}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404a1d9",
   "metadata": {},
   "source": [
    "### B. Công thức cập nhật trong SGD\n",
    "\n",
    "Ta tối thiểu hóa hàm mất mát (cho toàn bộ dữ liệu quan sát được):\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{(u,i)\\in\\mathcal{D}} \\frac{1}{2}(r_{ui} - p_u^\\top q_i)^2 + \\frac{\\lambda}{2}\\big(|p_u|^2 + |q_i|^2\\big)\n",
    "$$\n",
    "đặt sai số (prediction error) cho một cặp $(u,i)$ là\n",
    "$$\n",
    "e_{ui} = r_{ui} - p_u^\\top q_i.\n",
    "$$\n",
    "\n",
    "Với chuẩn viết có hệ số $1/2$ phía trước bình phương, gradient theo $p_u$ và $q_i$ của thành phần mất mát tại cặp $(u,i)$ là:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial p_u}\\Big(\\tfrac{1}{2} e_{ui}^2 + \\tfrac{\\lambda}{2}|p_u|^2\\Big)\n",
    "&= - e_{ui} q_i + \\lambda p_u,\\newline\n",
    "\\frac{\\partial}{\\partial q_i}\\Big(\\tfrac{1}{2} e_{ui}^2 + \\tfrac{\\lambda}{2}|q_i|^2\\Big)\n",
    "&= - e_{ui} p_u + \\lambda q_i.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Áp dụng quy tắc cập nhật SGD với learning rate (\\eta) (cập nhật theo hướng ngược gradient):\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p_u &\\leftarrow p_u - \\eta\\Big(- e_{ui} q_i + \\lambda p_u\\Big)\n",
    "= p_u + \\eta\\big(e_{ui} q_i - \\lambda p_u\\big),\\newline\n",
    "q_i &\\leftarrow q_i - \\eta\\Big(- e_{ui} p_u + \\lambda q_i\\Big)\n",
    "= q_i + \\eta\\big(e_{ui} p_u - \\lambda q_i\\big).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Ghi chú về các dạng khác nhau của công thức:** Một số hàm mất mát không có hệ số $1/2$ (ví dụ $(r-\\hat r)^2 + \\lambda|.|^2$), thì gradient sẽ chứa nhân tố $2$ và cập nhật sẽ có thêm hệ số $2$. Người thực nghiệm thường gộp hệ số $2$ vào $\\eta$ (hoặc dùng biểu thức có $1/2$ như trên) để có dạng cập nhật đơn giản như trình bày (nhưng cuối cùng về mục tiêu tối ưu vẫn như nhau).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e786a7",
   "metadata": {},
   "source": [
    "\n",
    "### C. Công thức cập nhật trong ALS (Alternating Least Squares)\n",
    "\n",
    "Ý tưởng là tách bài toán tối ưu đồng thời theo $P$ và $Q$ thành hai bước lặp: cố định $Q$ rồi tối ưu $P$ (từng hàng $p_u$ một), sau đó cố định $P$ và tối ưu $Q$. Với định nghĩa mất mát toàn cục\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{(u,i)\\in\\mathcal{D}} (r_{ui} - p_u^\\top q_i)^2 + \\lambda\\Big(\\sum_u |p_u|^2 + \\sum_i |q_i|^2\\Big),\n",
    "$$\n",
    "xét một user cụ thể $u$. Gọi $I_u$ là tập các item mà user $u$ đã đánh giá; xây hai đối tượng:\n",
    "\n",
    "* $r_u\\in\\mathbb{R}^{|I_u|}$: vector giá trị rating quan sát (thứ tự tương ứng với $I_u$);\n",
    "* $Q_u\\in\\mathbb{R}^{|I_u|\\times K}$: ma trận có các hàng là $q_i^\\top$ với $i\\in I_u$.\n",
    "\n",
    "Khi cố định mọi $q_i$, bài toán đối với $p_u$ là:\n",
    "$$\n",
    "\\min_{p_u} ||r_u - Q_u p_u||^2 + \\lambda ||p_u||^2.\n",
    "$$\n",
    "Đây là bài toán least squares đã có công thức giải, công thức có dạng:\n",
    "$$\n",
    "(Q_u^\\top Q_u + \\lambda I_K) p_u = Q_u^\\top r_u.\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_u = (Q_u^\\top Q_u + \\lambda I)^{-1} Q_u^\\top r_u,\n",
    "$$\n",
    "\n",
    "Trong thực thi, $Q_u^\\top Q_u = \\sum_{i\\in I_u} q_i q_i^\\top$ (ma trận $K\\times K$) và $Q_u^\\top r_u = \\sum_{i\\in I_u} r_{ui}, q_i$ (vector kích thước $K$).  \n",
    "Tương tự, khi cố định $P$ ta có:\n",
    "$$\n",
    "q_i = (P_i^\\top P_i + \\lambda I)^{-1} P_i^\\top r_i\n",
    "$$\n",
    "với $P_i$ ma trận gồm các $p_u^\\top$ cho user đã đánh giá item $i$, và $r_i$ là vector rating quan sát cho item $i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e35947",
   "metadata": {},
   "source": [
    "## 8. Đóng góp\n",
    "\n",
    "* **Nguyễn Hoàng Phúc:** tiền xử lý dữ liệu, triển khai ALS, triển khai LSH, soạn và biên tập báo cáo.\n",
    "* **Phạm Trung Kỳ:** triển khai SVD, SGD, NCF, thực hiện thí nghiệm và soạn báo cáo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030770b8",
   "metadata": {},
   "source": [
    "## 9. Tham khảo\n",
    "\n",
    "\n",
    "* Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020). *Mathematics for Machine Learning*. Cambridge University Press. pp. 111–134.\n",
    "\n",
    "* GeeksforGeeks. (2025, September 30). Stochastic Gradient Descent. Retrieved from [https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)\n",
    "\n",
    "* CodeSignal. (2025). Implementing the Alternating Least Squares Algorithm. Retrieved from [https://codesignal.com/learn/courses/diving-deep-into-collaborative-filtering-techniques-with-als/lessons/implementing-the-alternating-least-squares-algorithm](https://codesignal.com/learn/courses/diving-deep-into-collaborative-filtering-techniques-with-als/lessons/implementing-the-alternating-least-squares-algorithm)\n",
    "\n",
    "* Pinecone. (2025). Locality Sensitive Hashing (LSH): The Illustrated Guide. Retrieved from [https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/](https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/)\n",
    "\n",
    "* GeeksforGeeks. (2025, July 23). Overfitting and Regularization in ML. Retrieved from [https://www.geeksforgeeks.org/machine-learning/overfitting-and-regularization-in-ml/](https://www.geeksforgeeks.org/machine-learning/overfitting-and-regularization-in-ml/)\n",
    "\n",
    "* Apache Spark. (2025). Machine Learning Library (MLlib) Guide. Retrieved from [https://spark.apache.org/docs/latest/ml-guide.html](https://spark.apache.org/docs/latest/ml-guide.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
